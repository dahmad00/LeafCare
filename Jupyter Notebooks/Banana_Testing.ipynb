{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SBYMgm0ZN8TD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 07:13:17.104601: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-18 07:13:17.104690: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-18 07:13:17.104721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-18 07:13:17.117042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D,  \\\n",
    "    Dropout, Dense, Input, concatenate,      \\\n",
    "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
    "    Flatten, BatchNormalization, Activation, MaxPooling2D, GlobalMaxPooling2D,\\\n",
    "    Reshape,  multiply, add, Permute\n",
    "\n",
    "import math\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "26T_hfJaOJc8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def read_images(dir):\n",
    "\n",
    "    supported_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "    image_list = []\n",
    "    count = 0\n",
    "    # Walk through the directory and read images\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            file_extension = os.path.splitext(file)[-1].lower()\n",
    "\n",
    "            # Check if the file is a .jpg or .jpeg image\n",
    "            if file_extension in supported_extensions:\n",
    "                image_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    image = imageio.imread(image_path)\n",
    "                    image1 = image\n",
    "\n",
    "                    image = np.asarray(image)\n",
    "                    del image1\n",
    "                    image_list.append(image)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading image {image_path}: {e}\")\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % 100 == 0:\n",
    "              print(str(count) + \" images read\")\n",
    "\n",
    "\n",
    "    return image_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hpyn8jKJOwKe",
    "outputId": "3e6b31d7-0c78-41fc-f8ad-c02c9b1438cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96387/1347079695.py:21: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images read\n",
      "200 images read\n",
      "100 images read\n",
      "200 images read\n",
      "100 images read\n",
      "100 images read\n",
      "200 images read\n"
     ]
    }
   ],
   "source": [
    "# Train data directories\n",
    "base_train_dir = '../workspace/Banana2/V2/Test/'\n",
    "\n",
    "# Reading images for new classes\n",
    "cordana = read_images(os.path.join(base_train_dir, 'cordana'))\n",
    "healthy = read_images(os.path.join(base_train_dir, 'healthy'))  # This class remains common\n",
    "pestalotiopsis = read_images(os.path.join(base_train_dir, 'pestalotiopsis'))\n",
    "sigatoka = read_images(os.path.join(base_train_dir, 'sigatoka'))\n",
    "\n",
    "# Labeling for new train classes\n",
    "labels_cordana = np.zeros(len(cordana))\n",
    "labels_pestalotiopsis = np.ones(len(pestalotiopsis))\n",
    "# Healthy remains common, updating its label to reflect new class ordering\n",
    "labels_healthy = np.full(len(healthy), 2)\n",
    "labels_sigatoka = np.full(len(sigatoka), 3)\n",
    "\n",
    "# Combine train labels for new class setup\n",
    "labels = np.concatenate([\n",
    "    labels_cordana,\n",
    "    labels_pestalotiopsis,\n",
    "    labels_healthy,\n",
    "    labels_sigatoka\n",
    "])\n",
    "\n",
    "print(len(cordana) + len(pestalotiopsis) + len(healthy) + len(sigatoka))\n",
    "\n",
    "# Relative Frequencies for new classes\n",
    "# Create an array to store the frequencies of the lists\n",
    "class_freq = []\n",
    "\n",
    "# Append the lengths of the lists to the array for new classes\n",
    "class_freq.append(len(cordana))\n",
    "class_freq.append(len(pestalotiopsis))\n",
    "class_freq.append(len(healthy))\n",
    "class_freq.append(len(sigatoka))\n",
    "\n",
    "# Calculate the sum of all frequencies\n",
    "total_freq = sum(class_freq)\n",
    "\n",
    "# Calculate the relative frequencies for new classes\n",
    "relative_freq = [freq / total_freq for freq in class_freq]\n",
    "\n",
    "# Combine all images into a single list for processing or analysis\n",
    "images = cordana + pestalotiopsis + healthy + sigatoka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lXyFDHhfPBds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acufWSn9SSSd",
    "outputId": "b17402f7-98c8-4d82-838e-dc0ec3e7c56f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0DzCZeKePbmi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l_Cy4oSePipV"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeYTJ810RPRK",
    "outputId": "302387e8-aa6f-402a-d2ff-d3f6d38707d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "C0_0NzVfQ7Et",
    "outputId": "9232f3a3-1e6a-45cf-c137-43086dcfeb09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "heWW0AIORPOT"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "xNKL_TjwPsjK",
    "outputId": "230e2a2e-83a8-4ffa-ecd7-67522afe3ae3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 07:13:21.766007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79086 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:00:09.0, compute capability: 8.0\n",
      "2024-03-18 07:13:23.588029: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model('drive/MyDrive/C2_Models/best_epoch33_CustomModel_Full_part2 (7).keras')\n",
    "model = keras.models.load_model('../workspace/MobileNet/epoch15_model_part1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ToXtgRQhPu26"
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Find accuracy of model\n",
    "def find_accuracy(test,pred):\n",
    "    correct = 0\n",
    "    total = len(test)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        if test[i] == pred[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "# Map ANN outputs to classes\n",
    "def get_labels(y_pred_ann):\n",
    "    labels = []\n",
    "\n",
    "    for pred in y_pred_ann:\n",
    "        max_index = 0\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] > pred[max_index]:\n",
    "                max_index = i\n",
    "\n",
    "        labels.append(max_index)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def resize_images(images_list, width=128, height=128):\n",
    "    ia.seed(1)\n",
    "    # Define the resize augmentation\n",
    "    resize_augmenter = iaa.Resize({\"height\": height, \"width\": width})\n",
    "\n",
    "    resized_images = []\n",
    "\n",
    "    for image in images_list:\n",
    "        # Ensure the image is in RGB format (imgaug uses RGB by default)\n",
    "        if image.shape[-1] == 1:  # Grayscale image with single channel\n",
    "            image = np.repeat(image, 3, axis=-1)\n",
    "\n",
    "        # Apply the resize augmentation\n",
    "        augmented_image = resize_augmenter.augment_image(image)\n",
    "\n",
    "        # Append the augmented image to the result list\n",
    "        resized_images.append(augmented_image)\n",
    "\n",
    "    del images_list[:]\n",
    "    return resized_images\n",
    "\n",
    "def normalize_images(image_list):\n",
    "  for i in range(len(image_list)):\n",
    "    image = image_list[i].astype(np.float32) / 255.0\n",
    "    image_list[i] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NtwqXPYCPzK3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 07:13:28.241623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8905\n",
      "2024-03-18 07:13:28.310158: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images = resize_images(images, 224, 224)\n",
    "normalize_images(images)\n",
    "images = np.array(images)\n",
    "\n",
    "pred = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZYNQrRL8P2BI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "840\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "\n",
    "y_pred = get_labels(pred)\n",
    "total = len(y_pred)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == labels[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "\n",
    "print(correct)\n",
    "print(total)\n",
    "\n",
    "# Initialize variables to store weighted sums\n",
    "weighted_sum_sensitivity = 0\n",
    "weighted_sum_specificity = 0\n",
    "weighted_sum_precision = 0\n",
    "weighted_sum_accuracy = 0\n",
    "weighted_sum_f1 = 0\n",
    "\n",
    "class_metrics = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for j in range(len(y_pred)):\n",
    "        if labels[j] == i and y_pred[j] == i:\n",
    "            TP += 1\n",
    "        elif labels[j] != i and y_pred[j] == i:\n",
    "            FP += 1\n",
    "        elif labels[j] == i and y_pred[j] != i:\n",
    "            FN += 1\n",
    "        elif labels[j] != i and y_pred[j] != i:\n",
    "            TN += 1\n",
    "\n",
    "\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else -1\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else -1\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else -1\n",
    "    class_accuracy = (TP + TN) / (TP + FN + TN + FP)\n",
    "    recall = sensitivity\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else -1\n",
    "\n",
    "    class_metrics.append({\n",
    "        'class': int(i),\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'TN': TN,\n",
    "        'FN': FN,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'Precision': precision,\n",
    "        'Accuracy': class_accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'Relative Frequency': relative_freq[i]\n",
    "    })\n",
    "\n",
    "    # Calculate weighted sums\n",
    "    weighted_sum_sensitivity += sensitivity * relative_freq[i]\n",
    "    weighted_sum_specificity += specificity * relative_freq[i]\n",
    "    weighted_sum_precision += precision * relative_freq[i]\n",
    "    weighted_sum_accuracy += class_accuracy * relative_freq[i]\n",
    "    weighted_sum_f1 += f1 * relative_freq[i]\n",
    "\n",
    "\n",
    "\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ilVR7I2uP2iW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Class  Specificity  Sensitivity  Precision  Accuracy  F1 Score\n",
      "0             0        0.951        0.922      0.876     0.943     0.898\n",
      "1             1        0.974        0.843      0.836     0.956     0.840\n",
      "2             2        0.998        0.979      0.996     0.993     0.987\n",
      "3             3        0.990        0.943      0.976     0.975     0.959\n",
      "4  Weighted Avg        0.979        0.933      0.935     0.969     0.934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_metrics_dataframe(class_metrics):\n",
    "    # Create a dictionary to store the metrics for each class\n",
    "    metrics_dict = {\n",
    "        'Class': [metrics['class'] for metrics in class_metrics],\n",
    "        'Specificity': [metrics['Specificity'] for metrics in class_metrics],\n",
    "        'Sensitivity': [metrics['Sensitivity'] for metrics in class_metrics],\n",
    "        'Precision': [metrics['Precision'] for metrics in class_metrics],\n",
    "        'Accuracy': [metrics['Accuracy'] for metrics in class_metrics],\n",
    "        'F1 Score': [metrics['F1 Score'] for metrics in class_metrics]\n",
    "    }\n",
    "\n",
    "    # Create a Pandas DataFrame from the metrics dictionary\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Usage:\n",
    "# Assuming you have class_metrics list defined as in your previous code\n",
    "metrics_dataframe = create_metrics_dataframe(class_metrics)\n",
    "\n",
    "# Calculate weighted average metrics\n",
    "weighted_avg_metrics = {\n",
    "    'Class': 'Weighted Avg',\n",
    "    'Specificity': weighted_sum_specificity,  # Replace with your actual values\n",
    "    'Sensitivity': weighted_sum_sensitivity,  # Replace with your actual values\n",
    "    'Precision': weighted_sum_precision,      # Replace with your actual values\n",
    "    'Accuracy': weighted_sum_accuracy,        # Replace with your actual values\n",
    "    'F1 Score': weighted_sum_f1               # Replace with your actual values\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the weighted average metrics dictionary to a DataFrame for easier concatenation\n",
    "weighted_avg_metrics_df = pd.DataFrame([weighted_avg_metrics])\n",
    "\n",
    "# Concatenate the original dataframe with the new dataframe containing weighted average metrics\n",
    "metrics_dataframe = pd.concat([metrics_dataframe, weighted_avg_metrics_df], ignore_index=True)\n",
    "metrics_dataframe = metrics_dataframe.round(3)\n",
    "print(metrics_dataframe)\n",
    "\n",
    "metrics_dataframe.to_csv('classwise_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wxHMra-6P6EA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "3 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "2 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "1 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "0 0.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "1 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "0 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "3 3.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "3 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "3 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "3 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "1 1.0\n",
      "0 1.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "3 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "1 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "1 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "0 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "3 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n",
      "2 2.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "  print(y_pred[i], labels[i])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
