{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# # The extracted Google Drive file ID\n",
    "# file_id = '1cVbYDOE53znfikacsU0SvgaU1wNnx9TT'\n",
    "# url = f'https://drive.google.com/uc?id={file_id}'\n",
    "# output = 'Banana.zip'  # Choose a name for your file\n",
    "\n",
    "# # Download the file\n",
    "# gdown.download(url, output, quiet=False)\n",
    "\n",
    "# print(f\"File has been successfully downloaded to: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7dtX9thDxG_",
    "outputId": "d42931d8-61ca-4ca4-fa1f-9b52eb531f08"
   },
   "outputs": [],
   "source": [
    "# import zipfile as zf\n",
    "# files = zf.ZipFile(\"Banana.zip\", 'r')\n",
    "# files.extractall('Banana2')\n",
    "# files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cordana', 'healthy', 'pestalotiopsis', 'sigatoka', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('Banana2/V2/Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Specify the directory path\n",
    "# directory_path = '../workspace/Citrus/CitrusV1'\n",
    "\n",
    "# # List all files in the directory\n",
    "# for filename in os.listdir(directory_path):\n",
    "#     file_path = os.path.join(directory_path, filename)\n",
    "#     try:\n",
    "#         # Check if it is a file\n",
    "#         if os.path.isfile(file_path):\n",
    "#             os.remove(file_path)\n",
    "#             print(f\"{file_path} has been deleted.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QXl1wTYoDdBz",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 13:18:44.612434: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-30 13:18:44.637959: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-30 13:18:44.637980: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-30 13:18:44.637997: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-30 13:18:44.642546: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_images(dir):\n",
    "\n",
    "    supported_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "    image_list = []\n",
    "    count = 0\n",
    "    # Walk through the directory and read images\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            file_extension = os.path.splitext(file)[-1].lower()\n",
    "\n",
    "            # Check if the file is a .jpg or .jpeg image\n",
    "            if file_extension in supported_extensions:\n",
    "                image_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    image = imageio.imread(image_path)\n",
    "                    image1 = image\n",
    "\n",
    "                    image = np.asarray(image)\n",
    "                    del image1\n",
    "                    image_list.append(image)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading image {image_path}: {e}\")\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % 100 == 0:\n",
    "              print(str(count) + \" images read\")\n",
    "\n",
    "\n",
    "    return image_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hc04CAnpDnGK",
    "outputId": "2da9da6a-bcc3-4843-87df-9827c4ea2ba6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8GPaaxQYDqQM"
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "import copy\n",
    "\n",
    "def add_gaussian_noise(images, mean_range=(0, 15), std_range=(0, 0.15)):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.AdditiveGaussianNoise(loc=mean_range, scale=(0, 0.2*255))\n",
    "    ])\n",
    "\n",
    "    # Convert images to numpy array (imgaug requires numpy arrays)\n",
    "    # images_np = np.array(images)\n",
    "\n",
    "    # Perform augmentation on each image individually\n",
    "    augmented_images = [seq(image=image) for image in images]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "def random_crop(images, crop_percent=(0.1, 0.4)):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(percent=crop_percent)\n",
    "    ])\n",
    "\n",
    "    # Convert images to numpy array (imgaug requires numpy arrays)\n",
    "    # images_np = np.array(images)\n",
    "\n",
    "    # Perform augmentation on each image individually\n",
    "    augmented_images = [seq(image=image) for image in images]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "def random_rotate(images, rotation_range=(-360, 360)):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Rotate(rotate=rotation_range)\n",
    "    ])\n",
    "\n",
    "    # Convert images to numpy array (imgaug requires numpy arrays)\n",
    "    # images_np = np.array(images)\n",
    "\n",
    "    # Perform augmentation on each image individually\n",
    "    augmented_images = [seq(image=image) for image in images]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "def invert_images(images):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Add(value=(-20, 20))\n",
    "    ])\n",
    "\n",
    "    # Convert images to numpy array (imgaug requires numpy arrays)\n",
    "    # images_np = np.array(images)\n",
    "\n",
    "    # Perform augmentation on each image individually\n",
    "    augmented_images = [seq(image=image) for image in images]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "def adjust_brightness(images, brightness_range=(-65, 65)):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline for adjusting brightness\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Multiply((1.0 + brightness_range[0] / 100.0, 1.0 + brightness_range[1] / 100.0))\n",
    "    ])\n",
    "\n",
    "\n",
    "    augmented_images = [seq(image=image) for image in images]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "def scale_images(images, scale_factor = (0.3, 1.8)):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline for scaling images\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Affine(scale=scale_factor)\n",
    "    ])\n",
    "\n",
    "    augmented_images = [seq(image=image) for image in images]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "def add_contrast(images, contrast_factor=(0.5, 1.5)):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline for adding contrast\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.ContrastNormalization(alpha=contrast_factor)\n",
    "    ])\n",
    "\n",
    "    # Convert images to numpy array (imgaug requires numpy arrays)\n",
    "    images_np = np.array(images)\n",
    "\n",
    "    # Perform augmentation on each image individually\n",
    "    augmented_images = [seq(image=image) for image in images_np]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "def flip_images(images, flip_probability=0.5):\n",
    "    ia.seed(1)\n",
    "    # Define the augmentation pipeline for randomly flipping images\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Sometimes(flip_probability, iaa.Fliplr(1.0)),  # Horizontal flips\n",
    "        iaa.Sometimes(flip_probability, iaa.Flipud(1.0))   # Vertical flips\n",
    "    ])\n",
    "\n",
    "    # Convert images to numpy array (imgaug requires numpy arrays)\n",
    "    images_np = np.array(images)\n",
    "\n",
    "    # Perform augmentation on each image individually\n",
    "    augmented_images = [seq(image=image) for image in images_np]\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "# discard images according to ratio\n",
    "def discard_images(images, discard_ratio=0.5):\n",
    "    random.seed(10)\n",
    "    # Calculate the number of images to discard based on the discard_ratio\n",
    "    num_images_to_discard = int(len(images) * discard_ratio)\n",
    "\n",
    "    # Create a copy of the input list to avoid modifying the original list\n",
    "    remaining_images = images[:]\n",
    "\n",
    "    # Randomly discard a portion of the images\n",
    "    random.shuffle(remaining_images)\n",
    "    remaining_images = remaining_images[num_images_to_discard:]\n",
    "\n",
    "    return remaining_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resize_images(images_list, width=128, height=128):\n",
    "    ia.seed(1)\n",
    "    # Define the resize augmentation\n",
    "    resize_augmenter = iaa.Resize({\"height\": height, \"width\": width})\n",
    "\n",
    "    resized_images = []\n",
    "\n",
    "    for image in images_list:\n",
    "        # Ensure the image is in RGB format (imgaug uses RGB by default)\n",
    "        if image.shape[-1] == 1:  # Grayscale image with single channel\n",
    "            image = np.repeat(image, 3, axis=-1)\n",
    "\n",
    "        # Apply the resize augmentation\n",
    "        augmented_image = resize_augmenter.augment_image(image)\n",
    "\n",
    "        # Append the augmented image to the result list\n",
    "        resized_images.append(augmented_image)\n",
    "\n",
    "    del images_list[:]\n",
    "    return resized_images\n",
    "\n",
    "def keep_n_images(images, n_to_keep):\n",
    "    random.seed(10)\n",
    "    if n_to_keep >= len(images):\n",
    "        return images  # Keep all images if n_to_keep is greater than or equal to the image count\n",
    "\n",
    "    # Randomly shuffle the images list\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Keep the first n_to_keep images and discard the rest\n",
    "    kept_images = images[:n_to_keep]\n",
    "\n",
    "    # Create a copy of the kept images list\n",
    "    kept_images_copy = copy.deepcopy(kept_images)\n",
    "\n",
    "    # Clear the original images list to free memory\n",
    "    del images[:]\n",
    "\n",
    "    return kept_images_copy\n",
    "\n",
    "\n",
    "def normalize_images(images):    \n",
    "    # Convert the list of images to a NumPy array first\n",
    "    images_array = np.array(images)\n",
    "    \n",
    "    # Normalize the entire array in one operation to save memory\n",
    "    normalized_images_array = images_array / 255.0\n",
    "    \n",
    "    return normalized_images_array\n",
    "\n",
    "def discard_images(lst, percent_to_discard):\n",
    "    # Calculate the number of images to discard\n",
    "    num_images_to_discard = int(len(lst) * percent_to_discard)\n",
    "    \n",
    "    # Generate a list of unique indices to discard\n",
    "    indices_to_discard = random.sample(range(len(lst)), num_images_to_discard)\n",
    "    \n",
    "    # For each index to discard, if there's a need for explicit clean-up (e.g., closing a file or freeing resources), do it here\n",
    "    for index in indices_to_discard:\n",
    "        image = lst[index]\n",
    "        # If the image is an object that requires closing or special disposal, do it here\n",
    "        # For example, if image objects are from PIL, you might need to call image.close() if they are open files\n",
    "        # Note: This is only necessary if your image objects require explicit clean-up\n",
    "    \n",
    "    # Create a new list excluding the indices to discard\n",
    "    modified_lst = [lst[i] for i in range(len(lst)) if i not in indices_to_discard]\n",
    "    \n",
    "    return modified_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOMlfHOEDeKR",
    "outputId": "f7460548-ae95-422e-cc07-51f934c72c6d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13185/1632636461.py:20: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images read\n",
      "100 images read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:866: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "/usr/local/lib/python3.11/dist-packages/PIL/JpegImagePlugin.py:834: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images read\n",
      "200 images read\n",
      "300 images read\n",
      "400 images read\n",
      "Length of Cordana train: 122\n",
      "Length of Healthy train: 89\n",
      "Length of Pestalotiopsis train: 133\n",
      "Length of Sigatoka train: 433\n",
      "Length of Cordana test: 20\n",
      "Length of Healthy test: 20\n",
      "Length of Pestalotiopsis test: 20\n",
      "Length of Sigatoka test: 20\n",
      "Total length of all train parts: 777\n",
      "Total length of all test parts: 80\n",
      "Total length of all parts: 857\n"
     ]
    }
   ],
   "source": [
    "base_train_dir = '../workspace/Banana2/V2/Train'\n",
    "base_test_dir = '../workspace/Banana2/V2/Val'\n",
    "\n",
    "# Train data directories\n",
    "cordana_train = read_images(os.path.join(base_train_dir, 'cordana'))\n",
    "healthy_train = read_images(os.path.join(base_train_dir, 'healthy'))\n",
    "pestalotiopsis_train = read_images(os.path.join(base_train_dir, 'pestalotiopsis'))\n",
    "sigatoka_train = read_images(os.path.join(base_train_dir, 'sigatoka'))\n",
    "\n",
    "# Test data directories\n",
    "cordana_test = read_images(os.path.join(base_test_dir, 'cordana'))\n",
    "healthy_test = read_images(os.path.join(base_test_dir, 'healthy'))\n",
    "pestalotiopsis_test = read_images(os.path.join(base_test_dir, 'pestalotiopsis'))\n",
    "sigatoka_test = read_images(os.path.join(base_test_dir, 'sigatoka'))\n",
    "\n",
    "# For training classes\n",
    "print(\"Length of Cordana train:\", len(cordana_train))\n",
    "print(\"Length of Healthy train:\", len(healthy_train))\n",
    "print(\"Length of Pestalotiopsis train:\", len(pestalotiopsis_train))\n",
    "print(\"Length of Sigatoka train:\", len(sigatoka_train))\n",
    "\n",
    "# For test classes\n",
    "print(\"Length of Cordana test:\", len(cordana_test))\n",
    "print(\"Length of Healthy test:\", len(healthy_test))\n",
    "print(\"Length of Pestalotiopsis test:\", len(pestalotiopsis_test))\n",
    "print(\"Length of Sigatoka test:\", len(sigatoka_test))\n",
    "\n",
    "# Calculate the lengths of all train parts\n",
    "train_lengths = len(cordana_train) + len(healthy_train) + len(pestalotiopsis_train) + len(sigatoka_train)\n",
    "\n",
    "# Calculate the lengths of all test parts\n",
    "test_lengths = len(cordana_test) + len(healthy_test) + len(pestalotiopsis_test) + len(sigatoka_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total length of all train parts:\", train_lengths)\n",
    "print(\"Total length of all test parts:\", test_lengths)\n",
    "\n",
    "# Calculate the total length of all parts\n",
    "total_length = train_lengths + test_lengths\n",
    "\n",
    "# Print the results\n",
    "print(\"Total length of all parts:\", total_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTks90BUDq62",
    "outputId": "b73b85b4-ff77-49ad-f68b-17a80d7564be"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Assuming images for each class have already been loaded in the variables:\n",
    "# cordana_train_images, healthy_train_images, pestalotiopsis_train_images, sigatoka_train_images\n",
    "# cordana_test_images, healthy_test_images, pestalotiopsis_test_images, sigatoka_test_images\n",
    "\n",
    "# Function to process and augment images for a given class\n",
    "def process_images(images, discard_percentage):\n",
    "    # Process and augment the original images\n",
    "    images_all = (\n",
    "        add_gaussian_noise(images) +\n",
    "        random_crop(images) +\n",
    "        invert_images(images) +\n",
    "        adjust_brightness(images) +\n",
    "        scale_images(images) +\n",
    "        random_rotate(images)\n",
    "    )\n",
    "    \n",
    "    # Discard a percentage of the augmented images\n",
    "    images_all = discard_images(images_all, discard_percentage)\n",
    "    \n",
    "    # Return the original images combined with the non-discarded augmented images\n",
    "    return images + images_all\n",
    "\n",
    "# Set the discard percentage to 0\n",
    "discard_percentage = 0\n",
    "\n",
    "# Process training images for new classes using already loaded images\n",
    "cordana_train = process_images(cordana_train, discard_percentage)\n",
    "healthy_train = process_images(healthy_train, discard_percentage)\n",
    "pestalotiopsis_train = process_images(pestalotiopsis_train, discard_percentage)\n",
    "sigatoka_train = process_images(sigatoka_train, discard_percentage)\n",
    "\n",
    "# Process testing images for new classes using already loaded images\n",
    "cordana_test = process_images(cordana_test, discard_percentage)\n",
    "healthy_test = process_images(healthy_test, discard_percentage)\n",
    "pestalotiopsis_test = process_images(pestalotiopsis_test, discard_percentage)\n",
    "sigatoka_test = process_images(sigatoka_test, discard_percentage)\n",
    "\n",
    "\n",
    "# Generate training labels\n",
    "labels_cordana_train = np.zeros(len(cordana_train))\n",
    "labels_healthy_train = np.ones(len(healthy_train))\n",
    "labels_pestalotiopsis_train = np.full(len(pestalotiopsis_train), 2)\n",
    "labels_sigatoka_train = np.full(len(sigatoka_train), 3)\n",
    "\n",
    "# Combine training labels\n",
    "labels_train = np.concatenate([\n",
    "    labels_cordana_train,\n",
    "    labels_healthy_train,\n",
    "    labels_pestalotiopsis_train,\n",
    "    labels_sigatoka_train\n",
    "])\n",
    "\n",
    "# Generate testing labels\n",
    "labels_cordana_test = np.zeros(len(cordana_test))\n",
    "labels_healthy_test = np.ones(len(healthy_test))\n",
    "labels_pestalotiopsis_test = np.full(len(pestalotiopsis_test), 2)\n",
    "labels_sigatoka_test = np.full(len(sigatoka_test), 3)\n",
    "\n",
    "# Combine testing labels\n",
    "labels_test = np.concatenate([\n",
    "    labels_cordana_test,\n",
    "    labels_healthy_test,\n",
    "    labels_pestalotiopsis_test,\n",
    "    labels_sigatoka_test\n",
    "])\n",
    "\n",
    "dim = 224  # Desired size for resizing images\n",
    "\n",
    "\n",
    "# Resize training images\n",
    "cordana_train_resized = resize_images(cordana_train, dim, dim)\n",
    "healthy_train_resized = resize_images(healthy_train, dim, dim)\n",
    "pestalotiopsis_train_resized = resize_images(pestalotiopsis_train, dim, dim)\n",
    "sigatoka_train_resized = resize_images(sigatoka_train, dim, dim)\n",
    "\n",
    "# Concatenate resized training images\n",
    "images_train = np.concatenate([\n",
    "    cordana_train_resized,\n",
    "    healthy_train_resized,\n",
    "    pestalotiopsis_train_resized,\n",
    "    sigatoka_train_resized\n",
    "])\n",
    "\n",
    "# Resize testing images\n",
    "cordana_test_resized = resize_images(cordana_test, dim, dim)\n",
    "healthy_test_resized = resize_images(healthy_test, dim, dim)\n",
    "pestalotiopsis_test_resized = resize_images(pestalotiopsis_test, dim, dim)\n",
    "sigatoka_test_resized = resize_images(sigatoka_test, dim, dim)\n",
    "\n",
    "# Concatenate resized testing images\n",
    "images_test = np.concatenate([\n",
    "    cordana_test_resized,\n",
    "    healthy_test_resized,\n",
    "    pestalotiopsis_test_resized,\n",
    "    sigatoka_test_resized\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Correcting the discard percentage to match the description\n",
    "# # discard_percentage = 0.9\n",
    "\n",
    "# # Overwrite each class variable with the reduced dataset after discarding 52% of images\n",
    "# # bacterial_spot_all = discard_images(bacterial_spot_all, 1)\n",
    "# early_blight_all = discard_images(early_blight_all, 0.81)\n",
    "# healthy_all = discard_images(healthy_all, 0.93) \n",
    "# # late_blight_all = discard_images(late_blight_all, 1)\n",
    "# leaf_mold_all = discard_images(leaf_mold_all, 0.8)\n",
    "# mosaic_virus_all = discard_images(mosaic_virus_all, 0.16)\n",
    "# septoria_leaf_spot_all = discard_images(septoria_leaf_spot_all, 0.96)\n",
    "# spider_mites_all = discard_images(spider_mites_all, 0.96)\n",
    "# target_spot_all = discard_images(target_spot_all, 0.91)\n",
    "# # yellow_leaf_curl_virus_all = discard_images(yellow_leaf_curl_virus_all, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HaxJ-J5qk8QI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the percentage of images to discard\n",
    "# discard_percentage = 0.7  # This means 50% of the data will be discarded\n",
    "\n",
    "# # Apply the discard_images function to each dataset with the defined discard percentage\n",
    "# bacterial_spot_train = discard_images(bacterial_spot_train, discard_percentage)\n",
    "# early_blight_train = discard_images(early_blight_train, discard_percentage)\n",
    "# healthy_train = discard_images(healthy_train, discard_percentage)\n",
    "# late_blight_train = discard_images(late_blight_train, discard_percentage)\n",
    "# leaf_mold_train = discard_images(leaf_mold_train, discard_percentage)\n",
    "# mosaic_virus_train = discard_images(mosaic_virus_train, discard_percentage)\n",
    "# septoria_leaf_spot_train = discard_images(septoria_leaf_spot_train, discard_percentage)\n",
    "# spider_mites_train = discard_images(spider_mites_train, discard_percentage)\n",
    "# target_spot_train = discard_images(target_spot_train, discard_percentage)\n",
    "# yellow_leaf_curl_virus_train = discard_images(yellow_leaf_curl_virus_train, discard_percentage)\n",
    "\n",
    "# # After executing the above lines, each dataset variable will now reference a subset\n",
    "# that retains only 50% of the original images, since we're\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBt4R0viD3Pz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[131, 138, 104],\n",
       "        [131, 138, 104],\n",
       "        [130, 137, 104],\n",
       "        ...,\n",
       "        [ 92, 117,   0],\n",
       "        [ 94, 114,   0],\n",
       "        [101, 121,   8]],\n",
       "\n",
       "       [[137, 144, 111],\n",
       "        [137, 144, 111],\n",
       "        [130, 137, 104],\n",
       "        ...,\n",
       "        [ 95, 118,   2],\n",
       "        [ 99, 118,  10],\n",
       "        [100, 119,  12]],\n",
       "\n",
       "       [[147, 152, 122],\n",
       "        [147, 152, 122],\n",
       "        [141, 146, 116],\n",
       "        ...,\n",
       "        [ 95, 113,   5],\n",
       "        [106, 122,  24],\n",
       "        [114, 129,  38]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[120, 128,  91],\n",
       "        [126, 134,  97],\n",
       "        [126, 134,  97],\n",
       "        ...,\n",
       "        [ 66,  85,  30],\n",
       "        [ 78,  92,  41],\n",
       "        [ 84,  96,  46]],\n",
       "\n",
       "       [[125, 132,  98],\n",
       "        [128, 135, 101],\n",
       "        [129, 136, 102],\n",
       "        ...,\n",
       "        [ 60,  79,  24],\n",
       "        [ 66,  79,  26],\n",
       "        [ 69,  79,  27]],\n",
       "\n",
       "       [[133, 140, 107],\n",
       "        [130, 137, 104],\n",
       "        [128, 135, 102],\n",
       "        ...,\n",
       "        [ 62,  81,  26],\n",
       "        [ 62,  75,  22],\n",
       "        [ 59,  69,  17]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fm18BEYAxqG9"
   },
   "outputs": [],
   "source": [
    "\n",
    "images_train = normalize_images(images_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzUKhudfCMuR",
    "outputId": "3c35d115-5756-4376-f26e-366e44aee695",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# images_train[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gVOutQGDxwfT"
   },
   "outputs": [],
   "source": [
    "images_test = normalize_images(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vKXb38zpD6tC"
   },
   "outputs": [],
   "source": [
    "#TEST Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8X125FDBD9Pd",
    "outputId": "b7d3f1ef-a11b-4c69-b687-dc8c6dc67785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5439\n",
      "5439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[854, 623, 931, 3031]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(images_train))\n",
    "print(len(labels_train))\n",
    "\n",
    "counts = [0,0,0,0]\n",
    "\n",
    "for label in labels_train:\n",
    "    counts[int(label)] += 1\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SS_dvGp1D_zT",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ls1 = images_test\n",
    "ls2 = images_train\n",
    "\n",
    "images_test = np.array(images_test)\n",
    "images_train = np.array(images_train)\n",
    "\n",
    "del ls1\n",
    "del ls2\n",
    "\n",
    "\n",
    "shuffle_indices_train = np.random.permutation(len(images_train))\n",
    "shuffle_indices_test = np.random.permutation(len(images_test))\n",
    "\n",
    "\n",
    "images_train = images_train[shuffle_indices_train]\n",
    "labels_train = labels_train[shuffle_indices_train]\n",
    "\n",
    "images_test = images_test[shuffle_indices_test]\n",
    "labels_test = labels_test[shuffle_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9NsYhuwREBCD",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %load custom_callback.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Find accuracy of model\n",
    "def find_accuracy(test,pred):\n",
    "    correct = 0\n",
    "    total = len(test)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        if test[i] == pred[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "# Map ANN outputs to classes\n",
    "def get_labels(y_pred_ann):\n",
    "    labels = []\n",
    "\n",
    "    for pred in y_pred_ann:\n",
    "        max_index = 0\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] > pred[max_index]:\n",
    "                max_index = i\n",
    "\n",
    "        labels.append(max_index)\n",
    "\n",
    "    return labels\n",
    "\n",
    "# This callback prints accuracy by epoch information after each epoch\n",
    "class Save_Accuracy_By_Epoch(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.X_Test = test_data[0]\n",
    "        self.Y_Test = test_data[1]\n",
    "        self.accuracies = []\n",
    "        self.epochs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        y_pred = self.model.predict(self.X_Test)\n",
    "\n",
    "        if epoch == 4:\n",
    "            pass\n",
    "\n",
    "        y_pred = get_labels(y_pred)\n",
    "        accuracy = find_accuracy(self.Y_Test, y_pred)\n",
    "        self.epochs.append(epoch+1)\n",
    "        self.accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "        print(self.epochs)\n",
    "        print(self.accuracies)\n",
    "\n",
    "\n",
    "# This callback prints metrics for every class after each epoch\n",
    "class Save_Multiclass_Metrics_By_Epoch(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data, n_classes, save_after = 10,save_thresh =0.94, save_csv_path = 'results.csv', model_name = 'model.keras', decay_rate = 0.9, min_rate = 0.000032, save_folder_name = \".\"):\n",
    "        self.X_Test = test_data[0]\n",
    "        self.Y_Test = test_data[1]\n",
    "\n",
    "        self.min_rate = min_rate;\n",
    "        \n",
    "        self.epochs = []\n",
    "        self.n_classes = n_classes\n",
    "        self.save_after = save_after\n",
    "        self.save_csv_path = save_csv_path\n",
    "        self.save_folder_name = save_folder_name\n",
    "        self.model_name = model_name\n",
    "        self.max_accuracy = 0\n",
    "        self.save_thresh = save_thresh\n",
    "\n",
    "        self.mat_sensitivity = []\n",
    "        self.mat_specificity = []\n",
    "        self.mat_precision = []\n",
    "        self.mat_recall = []\n",
    "        self.mat_accuracy = []\n",
    "        self.mat_f1 = []\n",
    "        self.accuracies = []\n",
    "\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            self.mat_sensitivity.append([])\n",
    "            self.mat_specificity.append([])\n",
    "            self.mat_precision.append([])\n",
    "            self.mat_recall.append([])\n",
    "            self.mat_accuracy.append([])\n",
    "            self.mat_f1.append([])\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        y_pred = self.model.predict(self.X_Test)\n",
    "        y_pred = get_labels(y_pred)\n",
    "\n",
    "        total = len(self.Y_Test)\n",
    "\n",
    "        correct = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == self.Y_Test[i]:\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct/total\n",
    "        self.accuracies.append(correct / total)\n",
    "\n",
    "        best = False\n",
    "\n",
    "        if accuracy >= self.max_accuracy:\n",
    "            self.max_accuracy = accuracy\n",
    "            best = True\n",
    "\n",
    "\n",
    "        if accuracy > self.save_thresh:\n",
    "          best = True\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            TN = 0\n",
    "            FN = 0\n",
    "\n",
    "            for j in range(len(y_pred)):\n",
    "                if self.Y_Test[j] == i and y_pred[j] == i:\n",
    "                    TP += 1\n",
    "                elif self.Y_Test[j] != i and y_pred[j] == i:\n",
    "                    FP += 1\n",
    "                elif self.Y_Test[j] == i and y_pred[j] != i:\n",
    "                    FN += 1\n",
    "                elif self.Y_Test[j] != i and y_pred[j] != i:\n",
    "                    TN += 1\n",
    "\n",
    "            sensitivity = TP / (TP + FN) if (TP + FN) > 0 else -1\n",
    "            specificity = TN / (TN + FP) if (TN + FP) > 0 else -1\n",
    "            precision = TP / (TP + FP) if (TP + FP) > 0 else -1\n",
    "            recall = TP / (TP + FN) if (TP + FN) > 0 else -1\n",
    "            accuracy = (TP + TN) / (TP + FN + TN + FP)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else -1\n",
    "\n",
    "            self.mat_sensitivity[i].append(sensitivity)\n",
    "            self.mat_specificity[i].append(specificity)\n",
    "            self.mat_precision[i].append(precision)\n",
    "            self.mat_recall[i].append(recall)\n",
    "            self.mat_accuracy[i].append(accuracy)\n",
    "            self.mat_f1[i].append(f1)\n",
    "\n",
    "        self.epochs.append(int(epoch+1))\n",
    "\n",
    "        print(\"max Accuracy: \", self.max_accuracy, \"Learning Rate: \",self.model.optimizer.learning_rate.numpy())\n",
    "           \n",
    "\n",
    "        if self.model.optimizer.learning_rate <= self.min_rate :\n",
    "           self.model.stop_training = True\n",
    "\n",
    "        if (epoch + 1) % self.save_after == 0:\n",
    "            save_to_csv_file(self.save_csv_path, self.mat_sensitivity, self.mat_specificity, self.mat_precision, self.mat_recall, self.mat_accuracy, self.mat_f1, self.accuracies, self.epochs)\n",
    "            self.model.save(self.model_name)\n",
    "            if best:\n",
    "                self.model.save(self.save_folder_name + \"/epoch\" + str((epoch+1)) + \"_\" + self.model_name)\n",
    "            pass\n",
    "        \n",
    "\n",
    " \n",
    "\n",
    "def save_to_csv_file(path, mat_sensitivity, mat_specificity, mat_precision, mat_recall, mat_accuracy, mat_f1, accuracies, epochs):\n",
    "    mat_sensitivity = np.transpose(mat_sensitivity)\n",
    "    mat_specificity = np.transpose(mat_specificity)\n",
    "    mat_precision = np.transpose(mat_precision)\n",
    "    mat_recall = np.transpose(mat_recall)\n",
    "    mat_accuracy = np.transpose(mat_accuracy)\n",
    "    mat_f1 = np.transpose(mat_f1)\n",
    "    accuracies = np.reshape(accuracies, (-1,1))\n",
    "    epochs = np.reshape(epochs, (-1,1))\n",
    "\n",
    "    mat_join = np.concatenate((epochs,accuracies,mat_sensitivity, mat_specificity, mat_precision, mat_recall, mat_accuracy, mat_f1), axis = 1)\n",
    "\n",
    "    n = mat_sensitivity.shape[1]\n",
    "\n",
    "\n",
    "    col_array_sensitivity = list(range(n))\n",
    "    col_array_specificity = list(range(n))\n",
    "    col_array_precision = list(range(n))\n",
    "    col_array_recall = list(range(n))\n",
    "    col_array_accuracy = list(range(n))\n",
    "    col_array_f1 = list(range(n))\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        col_array_sensitivity[i] = 'sensitivity Class ' + str(col_array_sensitivity[i])\n",
    "        col_array_specificity[i] = 'specificity Class ' + str(col_array_specificity[i])\n",
    "        col_array_precision[i] = 'precision Class ' + str(col_array_precision[i])\n",
    "        col_array_recall[i] = 'recall Class ' + str(col_array_recall[i])\n",
    "        col_array_accuracy[i] = 'accuracy Class ' + str(col_array_accuracy[i])\n",
    "        col_array_f1[i] = 'f1 Class ' + str(col_array_f1[i])\n",
    "\n",
    "    cols = ['Epoch']+['overall_accuracy']+ col_array_sensitivity + col_array_specificity + col_array_precision + col_array_recall + col_array_accuracy + col_array_f1\n",
    "\n",
    "    mat_join = np.flip(mat_join, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        columns = cols,\n",
    "        data  = mat_join\n",
    "    )\n",
    "\n",
    "    df.to_csv(path, index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6ewhCiGnECZl"
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "labels_train_encoded = []\n",
    "for label in labels_train:\n",
    "    encoding = [0,0,0,0]\n",
    "    encoding[int(label)] = 1\n",
    "    labels_train_encoded.append(encoding)\n",
    "\n",
    "labels_train_encoded = np.array(labels_train_encoded)\n",
    "\n",
    "labels_test_encoded = []\n",
    "for label in labels_test:\n",
    "    encoding = [0,0,0,0]\n",
    "    encoding[int(label)] = 1\n",
    "    labels_test_encoded.append(encoding)\n",
    "\n",
    "labels_test_encoded = np.array(labels_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "CE-r9jApzZPw",
    "outputId": "e68e56bd-6e0b-48ff-c8d8-859baed905af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Lac-X6wtot2p"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "raw_model = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling=None\n",
    ")\n",
    "\n",
    "# for layer in raw_model.layers:\n",
    "#   layer.trainable = False\n",
    "\n",
    "model.add(raw_model)\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D65LqJMLpa75",
    "outputId": "822f0c2e-7870-4865-f727-56d5c38321f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 13:18:54.446674: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 64)                167520    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 218852 (854.89 KB)\n",
      "Trainable params: 216684 (846.42 KB)\n",
      "Non-trainable params: 2168 (8.47 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0003,\n",
    "    decay_steps=2000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "tf.keras.utils.set_random_seed(2)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss=loss, metrics = ['acc'])\n",
    "# model.compile(optimizer='adam', loss=loss, metrics = ['acc'], loss_weights=class_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYya-q-9BNKB",
    "outputId": "f94d2482-ffac-4d00-ece2-a39d7a64bf2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 13:19:00.091849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8905\n",
      "2024-03-30 13:19:00.149523: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-30 13:19:01.517592: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f76987cd9e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-30 13:19:01.517611: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-30 13:19:01.520953: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-30 13:19:01.580989: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 24ms/steploss: 1.0617 - \n",
      "max Accuracy:  0.5732142857142857 Learning Rate:  0.0003\n",
      "340/340 [==============================] - 25s 54ms/step - loss: 1.0617 - acc: 0.5769 - val_loss: 1.1442 - val_acc: 0.5732\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.9148 -\n",
      "max Accuracy:  0.6857142857142857 Learning Rate:  0.0003\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.9137 - acc: 0.6209 - val_loss: 0.9249 - val_acc: 0.6857\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.8474 -\n",
      "max Accuracy:  0.6857142857142857 Learning Rate:  0.0003\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.8469 - acc: 0.6501 - val_loss: 1.0049 - val_acc: 0.5946\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.8125 -\n",
      "max Accuracy:  0.6857142857142857 Learning Rate:  0.0003\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.8120 - acc: 0.6735 - val_loss: 0.9357 - val_acc: 0.6411\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.7515 -\n",
      "max Accuracy:  0.7571428571428571 Learning Rate:  0.0003\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.7539 - acc: 0.6996 - val_loss: 0.7627 - val_acc: 0.7571\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.7052 -\n",
      "max Accuracy:  0.7571428571428571 Learning Rate:  0.00027000002\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.7050 - acc: 0.7180 - val_loss: 0.7875 - val_acc: 0.7536\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.6805 -\n",
      "max Accuracy:  0.7571428571428571 Learning Rate:  0.00027000002\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.6808 - acc: 0.7336 - val_loss: 0.7462 - val_acc: 0.7339\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.6534 -\n",
      "max Accuracy:  0.8196428571428571 Learning Rate:  0.00027000002\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.6528 - acc: 0.7444 - val_loss: 0.5960 - val_acc: 0.8196\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.6262 -\n",
      "max Accuracy:  0.8232142857142857 Learning Rate:  0.00027000002\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.6261 - acc: 0.7639 - val_loss: 0.5131 - val_acc: 0.8232\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.5750 -\n",
      "max Accuracy:  0.8464285714285714 Learning Rate:  0.00027000002\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.5751 - acc: 0.7816 - val_loss: 0.5463 - val_acc: 0.8464\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.5389 -\n",
      "max Accuracy:  0.8464285714285714 Learning Rate:  0.00027000002\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.5397 - acc: 0.8009 - val_loss: 0.6566 - val_acc: 0.8018\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.5400 -\n",
      "max Accuracy:  0.8464285714285714 Learning Rate:  0.00024299999\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.5395 - acc: 0.8007 - val_loss: 0.5135 - val_acc: 0.8179\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.4947 -\n",
      "max Accuracy:  0.8464285714285714 Learning Rate:  0.00024299999\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.4948 - acc: 0.8163 - val_loss: 0.5603 - val_acc: 0.7786\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.4812 -\n",
      "max Accuracy:  0.8678571428571429 Learning Rate:  0.00024299999\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.4833 - acc: 0.8218 - val_loss: 0.4055 - val_acc: 0.8679\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.4860 -\n",
      "max Accuracy:  0.8678571428571429 Learning Rate:  0.00024299999\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.4856 - acc: 0.8224 - val_loss: 0.4389 - val_acc: 0.8625\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.4572 -\n",
      "max Accuracy:  0.8678571428571429 Learning Rate:  0.00024299999\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.4566 - acc: 0.8334 - val_loss: 0.4263 - val_acc: 0.8571\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.4239 -\n",
      "max Accuracy:  0.8910714285714286 Learning Rate:  0.00024299999\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.4240 - acc: 0.8513 - val_loss: 0.3660 - val_acc: 0.8911\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.4166 -\n",
      "max Accuracy:  0.8928571428571429 Learning Rate:  0.0002187\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.4176 - acc: 0.8551 - val_loss: 0.3519 - val_acc: 0.8929\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.3746 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.0002187\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3754 - acc: 0.8689 - val_loss: 0.3352 - val_acc: 0.9000\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.3953 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.0002187\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3952 - acc: 0.8641 - val_loss: 0.3544 - val_acc: 0.8786\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.3554 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.0002187\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3553 - acc: 0.8768 - val_loss: 0.3833 - val_acc: 0.8714\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.3633 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.0002187\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3629 - acc: 0.8733 - val_loss: 0.5746 - val_acc: 0.8393\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.3344 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.0002187\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3349 - acc: 0.8890 - val_loss: 0.3320 - val_acc: 0.8893\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.3331 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.00019682996\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3325 - acc: 0.8884 - val_loss: 0.3483 - val_acc: 0.8911\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.3058 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.00019682996\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.3052 - acc: 0.9003 - val_loss: 0.2953 - val_acc: 0.8893\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2904 -\n",
      "max Accuracy:  0.9 Learning Rate:  0.00019682996\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2905 - acc: 0.9002 - val_loss: 0.3643 - val_acc: 0.8839\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2899 -\n",
      "max Accuracy:  0.9160714285714285 Learning Rate:  0.00019682996\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2896 - acc: 0.9037 - val_loss: 0.2430 - val_acc: 0.9161\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2816 -\n",
      "max Accuracy:  0.9160714285714285 Learning Rate:  0.00019682996\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2812 - acc: 0.9022 - val_loss: 0.2435 - val_acc: 0.9161\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2755 -\n",
      "max Accuracy:  0.9232142857142858 Learning Rate:  0.00019682996\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2756 - acc: 0.9099 - val_loss: 0.2299 - val_acc: 0.9232\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2587 -\n",
      "max Accuracy:  0.9232142857142858 Learning Rate:  0.00017714698\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2589 - acc: 0.9149 - val_loss: 0.2372 - val_acc: 0.9107\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2756 -\n",
      "max Accuracy:  0.9232142857142858 Learning Rate:  0.00017714698\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2752 - acc: 0.9081 - val_loss: 0.2675 - val_acc: 0.9089\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2585 -\n",
      "max Accuracy:  0.9232142857142858 Learning Rate:  0.00017714698\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2580 - acc: 0.9193 - val_loss: 0.2363 - val_acc: 0.9143\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2631 -\n",
      "max Accuracy:  0.9232142857142858 Learning Rate:  0.00017714698\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2628 - acc: 0.9163 - val_loss: 0.2859 - val_acc: 0.9161\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2535 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00017714698\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2537 - acc: 0.9193 - val_loss: 0.2056 - val_acc: 0.9393\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2384 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00017714698\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2381 - acc: 0.9252 - val_loss: 0.2453 - val_acc: 0.9071\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2385 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.0001594323\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2381 - acc: 0.9243 - val_loss: 0.2112 - val_acc: 0.9357\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2305 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.0001594323\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2313 - acc: 0.9246 - val_loss: 0.2735 - val_acc: 0.9196\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2073 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.0001594323\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2068 - acc: 0.9366 - val_loss: 0.2147 - val_acc: 0.9321\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2375 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.0001594323\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2370 - acc: 0.9243 - val_loss: 0.2158 - val_acc: 0.9232\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2057 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.0001594323\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2056 - acc: 0.9356 - val_loss: 0.2115 - val_acc: 0.9321\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2069 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.0001594323\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2066 - acc: 0.9338 - val_loss: 0.2619 - val_acc: 0.9089\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1917 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00014348906\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1916 - acc: 0.9430 - val_loss: 0.2229 - val_acc: 0.9321\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1999 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00014348906\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2005 - acc: 0.9353 - val_loss: 0.1959 - val_acc: 0.9304\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.2004 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00014348906\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2005 - acc: 0.9404 - val_loss: 0.2237 - val_acc: 0.9232\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2039 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00014348906\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2042 - acc: 0.9397 - val_loss: 0.1970 - val_acc: 0.9286\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.2002 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00014348906\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.2004 - acc: 0.9390 - val_loss: 0.2135 - val_acc: 0.9214\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1863 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00014348906\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1873 - acc: 0.9419 - val_loss: 0.2051 - val_acc: 0.9375\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1842 -\n",
      "max Accuracy:  0.9392857142857143 Learning Rate:  0.00012914014\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1839 - acc: 0.9476 - val_loss: 0.1864 - val_acc: 0.9393\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1761 -\n",
      "max Accuracy:  0.9517857142857142 Learning Rate:  0.00012914014\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1758 - acc: 0.9483 - val_loss: 0.1645 - val_acc: 0.9518\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1702 -\n",
      "max Accuracy:  0.9517857142857142 Learning Rate:  0.00012914014\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1703 - acc: 0.9467 - val_loss: 0.1788 - val_acc: 0.9446\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1917 -\n",
      "max Accuracy:  0.9517857142857142 Learning Rate:  0.00012914014\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1928 - acc: 0.9441 - val_loss: 0.2141 - val_acc: 0.9357\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1734 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00012914014\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1735 - acc: 0.9487 - val_loss: 0.1907 - val_acc: 0.9536\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1746 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00011622612\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1744 - acc: 0.9478 - val_loss: 0.2870 - val_acc: 0.9161\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1608 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00011622612\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1613 - acc: 0.9527 - val_loss: 0.1818 - val_acc: 0.9429\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1648 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00011622612\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1652 - acc: 0.9483 - val_loss: 0.1851 - val_acc: 0.9375\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1681 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00011622612\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1681 - acc: 0.9527 - val_loss: 0.2228 - val_acc: 0.9321\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1548 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00011622612\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1556 - acc: 0.9557 - val_loss: 0.2284 - val_acc: 0.9214\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1564 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.00011622612\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1565 - acc: 0.9527 - val_loss: 0.1955 - val_acc: 0.9321\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1616 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.0001046035\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1614 - acc: 0.9511 - val_loss: 0.1878 - val_acc: 0.9411\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1422 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.0001046035\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1420 - acc: 0.9594 - val_loss: 0.1707 - val_acc: 0.9446\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1413 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.0001046035\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1412 - acc: 0.9601 - val_loss: 0.1758 - val_acc: 0.9464\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1399 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.0001046035\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1397 - acc: 0.9627 - val_loss: 0.2216 - val_acc: 0.9339\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1521 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.0001046035\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1518 - acc: 0.9566 - val_loss: 0.1954 - val_acc: 0.9321\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1628 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  0.0001046035\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1625 - acc: 0.9498 - val_loss: 0.1625 - val_acc: 0.9518\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1510 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  9.414316e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.1508 - acc: 0.9597 - val_loss: 0.1699 - val_acc: 0.9500\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1384 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  9.414316e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1384 - acc: 0.9584 - val_loss: 0.1730 - val_acc: 0.9536\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1400 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  9.414316e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1397 - acc: 0.9643 - val_loss: 0.2099 - val_acc: 0.9250\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1286 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  9.414316e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1284 - acc: 0.9630 - val_loss: 0.1752 - val_acc: 0.9446\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1260 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  9.414316e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.1259 - acc: 0.9658 - val_loss: 0.1594 - val_acc: 0.9518\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1414 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  9.414316e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1414 - acc: 0.9594 - val_loss: 0.1624 - val_acc: 0.9518\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1282 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  8.472884e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1288 - acc: 0.9687 - val_loss: 0.1611 - val_acc: 0.9446\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1308 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  8.472884e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1306 - acc: 0.9649 - val_loss: 0.1611 - val_acc: 0.9500\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1208 -\n",
      "max Accuracy:  0.9535714285714286 Learning Rate:  8.472884e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1212 - acc: 0.9675 - val_loss: 0.1561 - val_acc: 0.9446\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1296 -\n",
      "max Accuracy:  0.9571428571428572 Learning Rate:  8.472884e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.1293 - acc: 0.9647 - val_loss: 0.1404 - val_acc: 0.9571\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1115 -\n",
      "max Accuracy:  0.9571428571428572 Learning Rate:  8.472884e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1113 - acc: 0.9728 - val_loss: 0.1648 - val_acc: 0.9518\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1225 -\n",
      "max Accuracy:  0.9607142857142857 Learning Rate:  8.472884e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1227 - acc: 0.9673 - val_loss: 0.1435 - val_acc: 0.9607\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1259 -\n",
      "max Accuracy:  0.9607142857142857 Learning Rate:  7.625595e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1259 - acc: 0.9673 - val_loss: 0.1409 - val_acc: 0.9571\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1244 -\n",
      "max Accuracy:  0.9607142857142857 Learning Rate:  7.625595e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1246 - acc: 0.9676 - val_loss: 0.1744 - val_acc: 0.9554\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1256 -\n",
      "max Accuracy:  0.9607142857142857 Learning Rate:  7.625595e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1254 - acc: 0.9632 - val_loss: 0.1717 - val_acc: 0.9554\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1278 -\n",
      "max Accuracy:  0.9607142857142857 Learning Rate:  7.625595e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.1276 - acc: 0.9660 - val_loss: 0.1654 - val_acc: 0.9536\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1158 -\n",
      "max Accuracy:  0.9607142857142857 Learning Rate:  7.625595e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1156 - acc: 0.9689 - val_loss: 0.1571 - val_acc: 0.9589\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1175 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  7.625595e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1173 - acc: 0.9671 - val_loss: 0.1614 - val_acc: 0.9661\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1110 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.8630354e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.1111 - acc: 0.9708 - val_loss: 0.1730 - val_acc: 0.9446\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1255 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.8630354e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1253 - acc: 0.9671 - val_loss: 0.1804 - val_acc: 0.9446\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1169 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.8630354e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.1167 - acc: 0.9702 - val_loss: 0.1366 - val_acc: 0.9661\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1080 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.8630354e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1082 - acc: 0.9717 - val_loss: 0.1742 - val_acc: 0.9571\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1058 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.8630354e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1057 - acc: 0.9741 - val_loss: 0.1679 - val_acc: 0.9393\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1217 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.8630354e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1214 - acc: 0.9678 - val_loss: 0.1710 - val_acc: 0.9643\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1054 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.176732e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1052 - acc: 0.9706 - val_loss: 0.1675 - val_acc: 0.9482\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1043 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.176732e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1046 - acc: 0.9724 - val_loss: 0.1735 - val_acc: 0.9446\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1063 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.176732e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1063 - acc: 0.9721 - val_loss: 0.1918 - val_acc: 0.9411\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1028 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.176732e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1027 - acc: 0.9700 - val_loss: 0.1499 - val_acc: 0.9589\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0931 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.176732e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0929 - acc: 0.9770 - val_loss: 0.1448 - val_acc: 0.9607\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1001 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  6.176732e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1003 - acc: 0.9730 - val_loss: 0.1405 - val_acc: 0.9643\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0999 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.5590586e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0998 - acc: 0.9752 - val_loss: 0.1715 - val_acc: 0.9429\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0996 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.5590586e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0994 - acc: 0.9728 - val_loss: 0.1586 - val_acc: 0.9607\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1007 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.5590586e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1005 - acc: 0.9744 - val_loss: 0.1641 - val_acc: 0.9554\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0950 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.5590586e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0950 - acc: 0.9757 - val_loss: 0.1827 - val_acc: 0.9446\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.1083 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.5590586e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1081 - acc: 0.9737 - val_loss: 0.1490 - val_acc: 0.9554\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0908 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.5590586e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0916 - acc: 0.9752 - val_loss: 0.1415 - val_acc: 0.9589\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0968 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.0031525e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0968 - acc: 0.9785 - val_loss: 0.1497 - val_acc: 0.9607\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0961 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.0031525e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0959 - acc: 0.9755 - val_loss: 0.1459 - val_acc: 0.9589\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.1080 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.0031525e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.1078 - acc: 0.9722 - val_loss: 0.1609 - val_acc: 0.9464\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0957\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.0031525e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0956 - acc: 0.9768 - val_loss: 0.1385 - val_acc: 0.9643\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0995 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  5.0031525e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0996 - acc: 0.9730 - val_loss: 0.1398 - val_acc: 0.9625\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0879 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  4.502837e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0878 - acc: 0.9761 - val_loss: 0.1420 - val_acc: 0.9625\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0914 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  4.502837e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0915 - acc: 0.9763 - val_loss: 0.1555 - val_acc: 0.9643\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0925 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  4.502837e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0926 - acc: 0.9805 - val_loss: 0.1462 - val_acc: 0.9625\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0841 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  4.502837e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0839 - acc: 0.9800 - val_loss: 0.1493 - val_acc: 0.9661\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0926 -\n",
      "max Accuracy:  0.9660714285714286 Learning Rate:  4.502837e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0925 - acc: 0.9787 - val_loss: 0.1852 - val_acc: 0.9411\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0817 -\n",
      "max Accuracy:  0.9696428571428571 Learning Rate:  4.502837e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0816 - acc: 0.9811 - val_loss: 0.1389 - val_acc: 0.9696\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0948 -\n",
      "max Accuracy:  0.9696428571428571 Learning Rate:  4.0525538e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0946 - acc: 0.9761 - val_loss: 0.1611 - val_acc: 0.9643\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0934 -\n",
      "max Accuracy:  0.9696428571428571 Learning Rate:  4.0525538e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0934 - acc: 0.9763 - val_loss: 0.1392 - val_acc: 0.9607\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0883 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  4.0525538e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0900 - acc: 0.9785 - val_loss: 0.1567 - val_acc: 0.9714\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0835 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  4.0525538e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0839 - acc: 0.9820 - val_loss: 0.1473 - val_acc: 0.9661\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0895 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  4.0525538e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0893 - acc: 0.9794 - val_loss: 0.1515 - val_acc: 0.9625\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0906 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  4.0525538e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0905 - acc: 0.9779 - val_loss: 0.1506 - val_acc: 0.9625\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0945 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.6472975e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0946 - acc: 0.9798 - val_loss: 0.1962 - val_acc: 0.9482\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0816 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.6472975e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0815 - acc: 0.9812 - val_loss: 0.1640 - val_acc: 0.9518\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0786 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.6472975e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0785 - acc: 0.9825 - val_loss: 0.1290 - val_acc: 0.9696\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0891 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.6472975e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0891 - acc: 0.9774 - val_loss: 0.1736 - val_acc: 0.9536\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0824 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.6472975e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0824 - acc: 0.9820 - val_loss: 0.1546 - val_acc: 0.9589\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0778 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.6472975e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0778 - acc: 0.9812 - val_loss: 0.1509 - val_acc: 0.9643\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0848 -\n",
      "max Accuracy:  0.9714285714285714 Learning Rate:  3.282568e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0846 - acc: 0.9792 - val_loss: 0.1292 - val_acc: 0.9679\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0751 -\n",
      "max Accuracy:  0.9732142857142857 Learning Rate:  3.282568e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0750 - acc: 0.9838 - val_loss: 0.1347 - val_acc: 0.9732\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0877 -\n",
      "max Accuracy:  0.9732142857142857 Learning Rate:  3.282568e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0876 - acc: 0.9805 - val_loss: 0.1476 - val_acc: 0.9625\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0745 -\n",
      "max Accuracy:  0.975 Learning Rate:  3.282568e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0743 - acc: 0.9833 - val_loss: 0.1269 - val_acc: 0.9750\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0756 -\n",
      "max Accuracy:  0.975 Learning Rate:  3.282568e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0754 - acc: 0.9831 - val_loss: 0.1513 - val_acc: 0.9589\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0915 -\n",
      "max Accuracy:  0.975 Learning Rate:  3.282568e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0914 - acc: 0.9807 - val_loss: 0.1420 - val_acc: 0.9661\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0792 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.9543107e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0794 - acc: 0.9807 - val_loss: 0.1344 - val_acc: 0.9661\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0754 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.9543107e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0752 - acc: 0.9831 - val_loss: 0.1449 - val_acc: 0.9625\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0723 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.9543107e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0723 - acc: 0.9831 - val_loss: 0.1744 - val_acc: 0.9500\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0758 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.9543107e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0758 - acc: 0.9836 - val_loss: 0.1390 - val_acc: 0.9643\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0705 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.9543107e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0704 - acc: 0.9833 - val_loss: 0.1916 - val_acc: 0.9571\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0760 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.9543107e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0759 - acc: 0.9829 - val_loss: 0.1775 - val_acc: 0.9554\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0797 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.6588801e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0796 - acc: 0.9816 - val_loss: 0.1780 - val_acc: 0.9625\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0752\n",
      "max Accuracy:  0.975 Learning Rate:  2.6588801e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0751 - acc: 0.9831 - val_loss: 0.1406 - val_acc: 0.9679\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0775 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.6588801e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0774 - acc: 0.9818 - val_loss: 0.1765 - val_acc: 0.9589\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0720 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.6588801e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0718 - acc: 0.9842 - val_loss: 0.1464 - val_acc: 0.9661\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 25ms/steploss: 0.07\n",
      "max Accuracy:  0.975 Learning Rate:  2.6588801e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0748 - acc: 0.9831 - val_loss: 0.1425 - val_acc: 0.9643\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0733 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.6588801e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0732 - acc: 0.9829 - val_loss: 0.1458 - val_acc: 0.9661\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0734 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.3929919e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0757 - acc: 0.9820 - val_loss: 0.1456 - val_acc: 0.9643\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0718 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.3929919e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0717 - acc: 0.9842 - val_loss: 0.1366 - val_acc: 0.9661\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0629 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.3929919e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0628 - acc: 0.9868 - val_loss: 0.1465 - val_acc: 0.9696\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0673 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.3929919e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0672 - acc: 0.9866 - val_loss: 0.1433 - val_acc: 0.9732\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0816 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.3929919e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0814 - acc: 0.9820 - val_loss: 0.1647 - val_acc: 0.9589\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0752 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.3929919e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0751 - acc: 0.9829 - val_loss: 0.1349 - val_acc: 0.9732\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0664 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.1536925e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0665 - acc: 0.9871 - val_loss: 0.1422 - val_acc: 0.9696\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0708 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.1536925e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0707 - acc: 0.9827 - val_loss: 0.1291 - val_acc: 0.9714\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0712 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.1536925e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0711 - acc: 0.9831 - val_loss: 0.1417 - val_acc: 0.9679\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0867 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.1536925e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0866 - acc: 0.9800 - val_loss: 0.1253 - val_acc: 0.9714\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0734 -\n",
      "max Accuracy:  0.975 Learning Rate:  2.1536925e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0733 - acc: 0.9857 - val_loss: 0.1361 - val_acc: 0.9696\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0689 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.9383233e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0688 - acc: 0.9833 - val_loss: 0.1465 - val_acc: 0.9625\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0757 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.9383233e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0756 - acc: 0.9849 - val_loss: 0.1341 - val_acc: 0.9679\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0699 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.9383233e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0698 - acc: 0.9840 - val_loss: 0.1379 - val_acc: 0.9625\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0637 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.9383233e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0636 - acc: 0.9875 - val_loss: 0.1336 - val_acc: 0.9643\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0683 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.9383233e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0682 - acc: 0.9851 - val_loss: 0.1370 - val_acc: 0.9696\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0623 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.9383233e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0622 - acc: 0.9857 - val_loss: 0.1469 - val_acc: 0.9607\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0622 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.7444909e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0621 - acc: 0.9879 - val_loss: 0.1606 - val_acc: 0.9625\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0628 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.7444909e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0631 - acc: 0.9871 - val_loss: 0.1357 - val_acc: 0.9732\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0668 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.7444909e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0668 - acc: 0.9853 - val_loss: 0.1522 - val_acc: 0.9696\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0670 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.7444909e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0672 - acc: 0.9862 - val_loss: 0.1535 - val_acc: 0.9714\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0673 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.7444909e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0672 - acc: 0.9847 - val_loss: 0.1667 - val_acc: 0.9661\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0619 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.7444909e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0618 - acc: 0.9880 - val_loss: 0.1523 - val_acc: 0.9750\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0621 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.5700416e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0620 - acc: 0.9879 - val_loss: 0.1305 - val_acc: 0.9714\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0661 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.5700416e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0660 - acc: 0.9857 - val_loss: 0.1399 - val_acc: 0.9643\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0668 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.5700416e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0667 - acc: 0.9866 - val_loss: 0.1460 - val_acc: 0.9714\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0769 -\n",
      "max Accuracy:  0.975 Learning Rate:  1.5700416e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0768 - acc: 0.9849 - val_loss: 0.1391 - val_acc: 0.9750\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0650 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.5700416e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0649 - acc: 0.9851 - val_loss: 0.1295 - val_acc: 0.9768\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0628 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.5700416e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0627 - acc: 0.9868 - val_loss: 0.1351 - val_acc: 0.9714\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0621 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.4130377e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0620 - acc: 0.9866 - val_loss: 0.1508 - val_acc: 0.9661\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0698 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.4130377e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0699 - acc: 0.9846 - val_loss: 0.1464 - val_acc: 0.9696\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0617 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.4130377e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0616 - acc: 0.9879 - val_loss: 0.1490 - val_acc: 0.9696\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0680 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.4130377e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0679 - acc: 0.9860 - val_loss: 0.1373 - val_acc: 0.9679\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0710 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.4130377e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0714 - acc: 0.9851 - val_loss: 0.1557 - val_acc: 0.9661\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0656 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.4130377e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0654 - acc: 0.9877 - val_loss: 0.1366 - val_acc: 0.9714\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0660 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.2717339e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0659 - acc: 0.9869 - val_loss: 0.1409 - val_acc: 0.9661\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0601 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.2717339e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0603 - acc: 0.9895 - val_loss: 0.1374 - val_acc: 0.9714\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0635 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.2717339e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0636 - acc: 0.9877 - val_loss: 0.1380 - val_acc: 0.9732\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0576 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.2717339e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0576 - acc: 0.9895 - val_loss: 0.1421 - val_acc: 0.9732\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0635 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.2717339e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0635 - acc: 0.9862 - val_loss: 0.1242 - val_acc: 0.9732\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0706 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.2717339e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0705 - acc: 0.9847 - val_loss: 0.1325 - val_acc: 0.9714\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0647 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.1445603e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0646 - acc: 0.9875 - val_loss: 0.1410 - val_acc: 0.9732\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0606 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.1445603e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0605 - acc: 0.9875 - val_loss: 0.1543 - val_acc: 0.9679\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0542 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.1445603e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0541 - acc: 0.9906 - val_loss: 0.1430 - val_acc: 0.9714\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0683 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.1445603e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0682 - acc: 0.9858 - val_loss: 0.1446 - val_acc: 0.9696\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0589 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.1445603e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0588 - acc: 0.9890 - val_loss: 0.1401 - val_acc: 0.9679\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0662 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.1445603e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0661 - acc: 0.9862 - val_loss: 0.1588 - val_acc: 0.9607\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0660 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.0301043e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0659 - acc: 0.9868 - val_loss: 0.1649 - val_acc: 0.9625\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0597 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.0301043e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0596 - acc: 0.9879 - val_loss: 0.1681 - val_acc: 0.9643\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0637 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.0301043e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0637 - acc: 0.9864 - val_loss: 0.1518 - val_acc: 0.9661\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0620 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.0301043e-05\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0620 - acc: 0.9875 - val_loss: 0.1439 - val_acc: 0.9714\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0549 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.0301043e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0548 - acc: 0.9899 - val_loss: 0.1456 - val_acc: 0.9714\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0588 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  1.0301043e-05\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0588 - acc: 0.9892 - val_loss: 0.1372 - val_acc: 0.9696\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0595 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  9.270938e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0595 - acc: 0.9880 - val_loss: 0.1334 - val_acc: 0.9732\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0603 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  9.270938e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0604 - acc: 0.9860 - val_loss: 0.1386 - val_acc: 0.9732\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0663 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  9.270938e-06\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0662 - acc: 0.9864 - val_loss: 0.1406 - val_acc: 0.9696\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0653 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  9.270938e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0654 - acc: 0.9877 - val_loss: 0.1446 - val_acc: 0.9714\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0589 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  9.270938e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0588 - acc: 0.9901 - val_loss: 0.1505 - val_acc: 0.9696\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0620 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  9.270938e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0619 - acc: 0.9890 - val_loss: 0.1457 - val_acc: 0.9732\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0589 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  8.3438445e-06\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0588 - acc: 0.9873 - val_loss: 0.1368 - val_acc: 0.9661\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0637 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  8.3438445e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0636 - acc: 0.9875 - val_loss: 0.1390 - val_acc: 0.9696\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0581 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  8.3438445e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0580 - acc: 0.9892 - val_loss: 0.1419 - val_acc: 0.9679\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0679 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  8.3438445e-06\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0678 - acc: 0.9866 - val_loss: 0.1373 - val_acc: 0.9750\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0591 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  8.3438445e-06\n",
      "340/340 [==============================] - 15s 43ms/step - loss: 0.0590 - acc: 0.9888 - val_loss: 0.1487 - val_acc: 0.9732\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 23ms/steploss: 0.0569 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  7.5094586e-06\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0569 - acc: 0.9884 - val_loss: 0.1456 - val_acc: 0.9679\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0587 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  7.5094586e-06\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0586 - acc: 0.9866 - val_loss: 0.1433 - val_acc: 0.9732\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 24ms/steploss: 0.0697 -\n",
      "max Accuracy:  0.9767857142857143 Learning Rate:  7.5094586e-06\n",
      "340/340 [==============================] - 15s 44ms/step - loss: 0.0696 - acc: 0.9835 - val_loss: 0.1574 - val_acc: 0.9679\n",
      "Epoch 209/1000\n",
      "311/340 [==========================>...] - ETA: 1s - loss: 0.0627 - acc: 0.9883"
     ]
    }
   ],
   "source": [
    "history = model.fit(images_train, labels_train_encoded, batch_size=16, epochs=1000, validation_data=(images_test, labels_test_encoded), callbacks=[Save_Multiclass_Metrics_By_Epoch((images_test,labels_test), n_classes=10, save_after=1, save_csv_path=\"results_model_part1.csv\", model_name=\"model_part1.keras\", save_folder_name=\"Model\", min_rate=0.000004)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('../workspace/Model/epoch99_model_part1.keras')\n",
    "# model.save('tomato.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
